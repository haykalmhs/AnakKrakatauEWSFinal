{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDSN Waveform Ingestion and Processing\n",
    "\n",
    "Downloads I06AU and I52GB waveforms from IRIS FSDN services using Obpsy Mass Downloader and then converts them the .SAC file with it's stats for further processing. The .SAC files will be then further processed using \"Bartlett\" beamforming method and Adaptive F-Detector to identify signals most related to Anak Krakatau Volcanic Activity. These specific volcanic activity signals will be later ingested into the algorithm for the Deep Learning processing. This notebook will do as follows:\\\n",
    "\n",
    "This notebook consists of 3 parts:\n",
    "1. Dowloading Data using Obspy Mass Downloader\n",
    "2. Conversion of MSEED Files to .SAC\n",
    "3. Implementing FK Beamforming to each station group\n",
    "4. Running Adaptive F-Detector to Isolate relevant Waveform\n",
    "5. Calculating Best Beam using Laslo's Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/')\n",
    "\n",
    "import obspy\n",
    "from obspy import UTCDateTime, read, read_inventory\n",
    "from obspy.clients.fdsn.mass_downloader import GlobalDomain, \\\n",
    "    Restrictions, MassDownloader\n",
    "from obspy.core.util.attribdict import AttribDict\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from src.utils.converter import *\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Downloading Data Using Obspy Mass Downloader\n",
    "\n",
    "Download the data ranging from 2018-06-24T00:00:00 until 2019-09-03T00:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 I06AU Waveform Download\n",
    "\n",
    "domain = GlobalDomain()\n",
    "\n",
    "restrictions = Restrictions(\n",
    "    # Get data for a whole year.\n",
    "    starttime=obspy.UTCDateTime(2018, 6, 24),\n",
    "    endtime=obspy.UTCDateTime(2019, 9, 3),\n",
    "    # Chunk it to have one file per day.\n",
    "    chunklength_in_sec=86400,\n",
    "    network=\"IM\", station=\"I06H*\", location=\"\", channel=\"BDF\",\n",
    "    # The typical use case for such a data set are noise correlations where\n",
    "    # gaps are dealt with at a later stage.\n",
    "    reject_channels_with_gaps=False,\n",
    "    # Same is true with the minimum length. All data might be useful.\n",
    "    minimum_length=0.0,\n",
    "    # Guard against the same station having different names.\n",
    "    minimum_interstation_distance_in_m=100.0)\n",
    "\n",
    "mdl = MassDownloader(providers=[\"IRIS\"])\n",
    "mdl.download(domain, restrictions, mseed_storage=\"waveform_collection/I06AU/WAVEFORM_I06AU_MSEED\",\n",
    "             stationxml_storage=\"waveform_collection/I06AU/I06AU_STATIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 I52GB Waveform Download\n",
    "\n",
    "domain = GlobalDomain()\n",
    "\n",
    "restrictions = Restrictions(\n",
    "    starttime=obspy.UTCDateTime(2018, 6, 24),\n",
    "    endtime=obspy.UTCDateTime(2019, 9, 3),\n",
    "    chunklength_in_sec=86400,\n",
    "    network=\"IM\", station=\"I52H*\", location=\"\", channel=\"BDF\",\n",
    "    reject_channels_with_gaps=False,\n",
    "    minimum_length=0.0,\n",
    "    minimum_interstation_distance_in_m=100.0)\n",
    "\n",
    "\n",
    "mdl = MassDownloader(providers=[\"IRIS\"])\n",
    "mdl.download(domain, restrictions, mseed_storage=\"/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I52GB/I52GB_MSEED\",\n",
    "             stationxml_storage=\"/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I52GB/I52GB_STATIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conversion of MSEED Files to .SAC\n",
    "Converting MSEED Files to SAC Complete with Important Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 I06AU Waveform Conversion\n",
    "\n",
    "input_directory = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I06AU/I06AU_MSEED'\n",
    "output_directory = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I06AU/I06AU_SAC'\n",
    "stationxml_directory = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I06AU/I06AU_STATIONS'\n",
    "\n",
    "# Run the Function\n",
    "mseed_to_sac(input_directory, output_directory, stationxml_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 I52GB Waveform Conversion\n",
    "\n",
    "input_directory = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I52GB/I52GB_MSEED'\n",
    "output_directory = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I52GB/I52GB_SAC'\n",
    "stationxml_directory = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I52GB/I52GB_STATIONS'\n",
    "\n",
    "# Run the Function\n",
    "mseed_to_sac(input_directory, output_directory, stationxml_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bartlett FK Beamforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Running Beamforming on I06AU Waveform\n",
    "\n",
    "base_folder_path = '/run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I06AU/WAVEFORM_I06AU_SAC'\n",
    "df_grouped_file_paths = sac_path_grouping(base_folder_path)\n",
    "\n",
    "# Wrap the iterrows with tqdm to create a progress bar\n",
    "for index, row in tqdm(df_grouped_file_paths.iterrows(), total=df_grouped_file_paths.shape[0], desc=\"Processing\"):\n",
    "    # Construct the full path to the grouped files\n",
    "    full_grouped_path = f\"{base_folder_path}/{row['GroupedFilePath']}\"\n",
    "\n",
    "    # Prepare the CLI command\n",
    "    cli_command = f\"infrapy run_fk --local-wvfrms \\\"{full_grouped_path}\\\" --freq-min 0.7 --freq-max 4 --back-az-min 50 --back-az-max 60 --window-len 600 --sub-window-len 30 --window-step 300\"\n",
    "    \n",
    "    try:\n",
    "        # Execute the CLI command\n",
    "        subprocess.run(cli_command, shell=True, check=True)\n",
    "        print(f\"Command executed for: {full_grouped_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while running the command for {full_grouped_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Running Beamforming on I52GB Waveform\n",
    "\n",
    "base_folder_path = '/run/media/viblab/Markov11/Haykal/AnakKrakatauEWS/waveform_collection/I52GB/WAVEFORM_I52GB_SAC'\n",
    "df_grouped_file_paths = sac_path_grouping(base_folder_path)\n",
    "\n",
    "# Wrap the iterrows with tqdm to create a progress bar\n",
    "for index, row in tqdm(df_grouped_file_paths.iterrows(), total=df_grouped_file_paths.shape[0], desc=\"Processing\"):\n",
    "    # Construct the full path to the grouped files\n",
    "    full_grouped_path = f\"{base_folder_path}/{row['GroupedFilePath']}\"\n",
    "\n",
    "    # Prepare the CLI command\n",
    "    cli_command = f\"infrapy run_fk --local-wvfrms \\\"{full_grouped_path}\\\" --\"\n",
    "    \n",
    "    try:\n",
    "        # Execute the CLI command\n",
    "        subprocess.run(cli_command, shell=True, check=True)\n",
    "        print(f\"Command executed for: {full_grouped_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred while running the command for {full_grouped_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Adaptive F-Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Running AFD for I06AU Station\n",
    "\n",
    "folder_path = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I06AU/I06AU_FK_RESULTS'\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "full_paths = [os.path.join(folder_path, file) for file in files]\n",
    "\n",
    "# Using ThreadPoolExecutor to process files concurrently\n",
    "with ThreadPoolExecutor(8) as executor:\n",
    "    # Map the executor to the process_file function and the list of file paths\n",
    "    results = list(tqdm(executor.map(lambda file_path: subprocess.run(f\"infrapy run_fd --local-fk-label {file_path} --p-value 0.05 --back-az-width 5 --min-duration 25 --merge-dets 'False'\", shell=True), full_paths), total=len(full_paths), desc=\"Processing files\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing the files\n",
    "folder_path = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I52GB/I52GB_FK'\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "full_paths = [os.path.join(folder_path, file) for file in files]\n",
    "\n",
    "# Using ThreadPoolExecutor to process files concurrently\n",
    "with ThreadPoolExecutor(8) as executor:\n",
    "    # Map the executor to the process_file function and the list of file paths\n",
    "    results = list(tqdm(executor.map(lambda file_path: subprocess.run(f\"infrapy run_fd --local-fk-label {file_path} --p-value 0.05 --back-az-width 5\", shell=True), full_paths), total=len(full_paths), desc=\"Processing files\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Laslo's Best Beam Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/notebook/Best-Beam_ITeration/BEST-BEAM_DATABASE_Unique_6.csv'  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to generate CLI command for each row\n",
    "def generate_command(row):\n",
    "    return (\n",
    "        f\"infrapy utils best-beam --local-wvfrms '{row['SACFile']}' \"\n",
    "        f\"--local-fk-label '{row['FKResults']}' --signal-start '{row['Start']}' \"\n",
    "        f\"--signal-end '{row['End']}' --trace-vel {row['Trace Velocity']} \"\n",
    "        f\"--back-az {row['Back Azimuth']} --freq-min {row['Freq Min']} \"\n",
    "        f\"--freq-max {row['Freq Max']} --hold-figure False\"\n",
    "    )\n",
    "\n",
    "# Generating CLI commands for each row\n",
    "cli_commands = df.apply(generate_command, axis=1).tolist()\n",
    "\n",
    "# Function to execute a command\n",
    "def run_command(cmd):\n",
    "    try:\n",
    "        subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        return \"Success\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Failed: {e}\"\n",
    "\n",
    "# Running the commands concurrently and monitoring with tqdm\n",
    "with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "    results = list(tqdm(executor.map(run_command, cli_commands), total=len(cli_commands)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the folders containing the CSV files and output files\n",
    "csv_folder_path = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/notebook/Best-Beam_ITeration'\n",
    "output_folder_path = '/run/media/viblab/Markov2/Haykal/AnakKrakatauEWS/data/raw/I06AU/I06AU_FK_RESULTS_300/'\n",
    "\n",
    "def run_command_and_rename(cmd, csv_index, fk_label):\n",
    "    try:\n",
    "        # Execute the command\n",
    "        subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "        # Extract the timestamp part from the FKResults filename\n",
    "        timestamp_part = fk_label.split('/')[-1].replace('.fk_results.dat', '')\n",
    "\n",
    "        # Original and new output filename formats\n",
    "        original_output_file = os.path.join(output_folder_path, timestamp_part + \".best-beam.dat\")\n",
    "        new_output_filename = os.path.join(output_folder_path, f\"{csv_index}_{timestamp_part}.best-beam.dat\")\n",
    "\n",
    "        # Rename the file\n",
    "        if os.path.exists(original_output_file):\n",
    "            os.rename(original_output_file, new_output_filename)\n",
    "        return \"Success\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Failed: {e}\"\n",
    "\n",
    "csv_files = glob.glob(os.path.join(csv_folder_path, '*.csv'))\n",
    "for csv_index, file_path in enumerate(csv_files, start=1):\n",
    "    df = pd.read_csv(file_path)\n",
    "    cli_commands = df.apply(generate_command, axis=1).tolist()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "        futures = [executor.submit(run_command_and_rename, cmd, csv_index, row['FKResults']) for cmd, row in zip(cli_commands, df.to_dict('records'))]\n",
    "        results = list(tqdm((future.result() for future in futures), total=len(cli_commands)))\n",
    "\n",
    "    # Process results or perform additional actions as needed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infrapy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
